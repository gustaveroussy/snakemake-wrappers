---
title: "DESeq2 Report"
author:
    - BiGR, Gustave Roussy Institute
date: "`r format(Sys.time(), '%d %B, %Y')`"
params:
   rmd: "report.Rmd"
output:
  html_document:
  highlight: tango
  number_sections: no
  theme: ubuntu
  toc: yes
  toc_depth: 3
  toc_float:
    collapsed: no
    smooth_scroll: yes
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE
);
base::library(package = "DT", quietly = TRUE);
base::library(package = "readr", quietly = TRUE);
```

## DESeq2 result

```{r load_input}
gseapp_tsv_path <- base::as.character(
  x = snakemake@input[["gseapp_tsv"]]
);

volcano_path <- base::as.character(x = snakemake@input[["volcano"]]);
if (! base::startsWith("/", volcano_path)) {
  volcano_path <- base::file.path(getwd(), volcano_path);
}

pvalue_hist_path <- base::as.character(x = snakemake@input[["pval_hist"]]);
if (! base::startsWith("/", pvalue_hist_path)) {
  pvalue_hist_path <- base::file.path(getwd(), pvalue_hist_path);
}

pca_scree_path <- base::as.character(x = snakemake@input[["pca_scree"]]);
if (! base::startsWith("/", pca_scree_path)) {
  pca_scree_path <- base::file.path(getwd(), pca_scree_path);
}

pca_corrs_path <- base::as.character(x = snakemake@input[["pca_corrs"]]);
if (! base::startsWith("/", pca_corrs_path)) {
  pca_corrs_path <- base::file.path(getwd(), pca_corrs_path);
}

distro_expr_path <- base::as.character(x = snakemake@input[["distro_expr"]]);
if (! base::startsWith("/", distro_expr_path)) {
  distro_expr_path <- base::file.path(getwd(), distro_expr_path);
}

maplot_path <- base::as.character(x = snakemake@input[["maplot"]]);
if (! base::startsWith("/", maplot_path)) {
  maplot_path <- base::file.path(getwd(), maplot_path);
}

coldata_path <- base::as.character(x = snakemake@input[["coldata"]]);
if ((! base::startsWith("/", coldata_path)) & (! file.exists(coldata_path))) {
  print(coldata_path)
  coldata_path <- base::file.path(getwd(), coldata_path);
}

pca_path <- base::as.character(x = snakemake@input[["pca"]]);
if (! base::startsWith("/", pca_path)) {
  pca_path <- base::file.path(getwd(), pca_path);
}

results_name <- gseapp_tsv_path;
if ("results_name" %in% base::names(snakemake@params)) {
  results_name <- base::as.character(x = snakemake@params[["results_name"]])
}

alpha_threshold <- 0.05;
if ("alpha_threshold" %in% base::names(snakemake@params)) {
  alpha_threshold <- base::as.numeric(
    x = snakemake@params[["alpha_threshold"]]
  );
}

fc_threshold <- 1;
if ("fc_threshold" %in% base::names(snakemake@params)) {
  fc_threshold <- base::as.numeric(
    x = snakemake@params[["fc_threshold"]]
  );
}

gseapp_tsv <- readr::read_tsv(
  gseapp_tsv_path
) %>% dplyr::select(
  Gene = gene_name,
  Log2_FC = stat_change,
  Adjusted_PValue = padj,
  Regulation = cluster,
  Significance = significance
) %>% dplyr::mutate(
  Pubmed = base::paste0(
    "<a href='https://www.ncbi.nlm.nih.gov/gene/?term=",
    Gene,
    "'>",
    Gene,
    "</a>"
  ),
  GeneCards = base::paste0(
    "<a href='https://www.genecards.org/Search/Keyword?queryString=",
    Gene,
    "'>",
    Gene,
    "</a>"
  )
);

coldata <- readr::read_tsv(
  coldata_path
);
```

This is the result of the DESeq2 analysis of `r results_name`.

### Sample description

```{r datatable_coldata, results = "asis"}
DT::datatable(
  coldata,
  rownames = FALSE
);
```

### PCA

A [Principal Component Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) is a measure of the difference of the samples against each other. Each point on this graph represents a sample. When two points are close to each other, it means that they’re similar. When two points are far from each other, it means that they’re different.

The colors have been set in agreement with the conditions, so we expect all samples from one condition (= one color) to be confined in one section of the graph. We also expect the different conditions to be spread through the graph. Optimally, a straight line can separate the samples.

In a PCA, we try to represent the samples on a two dimension graph, while preserving the variance. On the X and Y axis, we can respectively find PC1 and PC2. These are axis of the component analysis. These two axis are those who explains at best the variance between samples.

```{r pca}
knitr::include_graphics(pca_path);
```

There are many axis on a PCA; at most, there are one minus the number of tests, so one minus the number of genes tested, so around 50.000 axes. Below, you shall find the loadings of each axes and the corresponding percentage of explained variance they represent.

This offers an insight of the future possible results of a differential analysis. In fact, the higher the axe percentage of variance explained is, the better the differential analysis will be. With cell strains, one can often see a strong first axe related to the initial hypothesis. With samples obtained from patients, this is more noisy.

```{r pca_scree}
knitr::include_graphics(pca_scree_path);
```

For each axe, one can compute correlations with experimental design and hypothesis. You can find these correlation results below. Remember, correlation is not causality.

```{r pca_corrs}
knitr::include_graphics(pca_corrs_path);
```

### Gene table

Please find below the list of analyzed genes. Genes with no expression in all samples were filtered out, so that the page is a bit smaller. Genes with no P-Value (for any reason) were filtered out, so that the page is a bit smaller.

The table below has the following columns:

*   *Gene*: The name of the gene
*   *Log2_FC*: The Log2(Fold Change), see Frequently Asked Questions below for more information.
*   *Adjusted_PValue*: The adjusted P-Value, see Frequently Asked Questions below for more information.
*   *Regulation*: A character string giving you a hint on the regulation flow
*   *Significance*: A character string giving you a hint on the differential expression result
*   *Pubmed*: A link to pubmed articles on this gene. Click to open a new page in your web browser.
*   *GeneCards*: A link to this gene card on GeneCards. Click to open a new page in your web browser.

```{r datatable_deseq2, results = "asis"}
DT::datatable(
  gseapp_tsv,
  rownames = FALSE,
  escape = FALSE
);
```

### Volcano plot

A volcano plot is a convenient way to see the distribution of differentially expressed genes.

A "good" volcano plot should display some kind of "V", no other shape. In the X axis, you can see the fold change, and on the Y axis, you have the $-Log_{10}(Adjusted P-Value)$. In conclusion, genes with a negative fold change will be on the left, positive fold change will be on the right, and genes with no change will be in the middle. Genes with good adjusted P-Values (differentially expressed) will be on the top of the graph (on each side of the V's branches) and non significant changes will be in the bottom of the graph.

Your bioinformatician can highlight any number of genes of interest on this graph.

```{r volcano}
knitr::include_graphics(volcano_path);
```

### Expression distribution

The distribution of the expression values is a good insight of potential normalization fails and/or sequencing bias. A "good" distribution shows comparable means and overlapping percentiles. Any important variation may lead to bias in the differential analysis.

```{r distro_expr}
knitr::include_graphics(distro_expr_path);
```

### P-Value Histogram

The P-Value Histogram is a convenient way to check weather the P-Values are well distributed across the genes.

A "good" P-Value histogram should display a High value on "zero" and low values elsewhere. On X axis, there are the ranges of P-Values. On the Y axis, there is a raw count of genes within the given P-Value range.

This however is a control used by bioinformaticians and multiple reason can explain a variation in this histogram.

```{r pval_hist}
knitr::include_graphics(pvalue_hist_path);
```

### MA-plot

The mean-average plot is a good control of sequencing and normalization bias.

A "good" MA-plot should be horizontal, noise should be more important on small expression values. On the X axis the gene expression value is represented, and the Y axis displays Fold Change.

```{r maplot}
knitr::include_graphics(maplot_path);
```


### Frequently Asked Questions

#### Fold change and significance

The Fold Change is a simple ratio over two observations:

$FC = \displaystyle \frac{mean(Expression gene A, condition 1)}{mean(Expression gene A, condition 2)}$

We use a $Log2(FC)$ for plotting convenience.

By itself, a Fold Change does not lead to any conclusion: a high fold change may be due to anything from the initial hypothesis to any other kind of external factor. That's why we use DESeq2 to perform the differential expression analysis, rather than a simple ratio.

The point of DESeq2 is to conclude, with a P-Value, weather the expression variation seems to be related to our initial hypothesis or not.

Let us consider the following cases, which are classic misleading cases in which a high Fold Change is **not** related to our initial hypothesis.

**Case 1: Out layers**

```{r fc_case_1, fig.cap = "Expression values of Gene1, condition A (blue) vs condition B (green)"}
barplot(c(2,6,4,4,2,20), names = c("S1", "S2", "S3", "S4", "S5", "S6"), col = c("lightblue", "lightblue", "lightblue", "seagreen", "seagreen", "seagreen"))
```

Here, the mean expression for the gene Gene1 for condition A is: `r mean(2, 6, 4)`. The mean expression for the gene Gene2 for condition B is: `r mean(2, 20, 4)`.

The mean expression in the two conditions are different, however, this difference is due to one single sample which is not behaving like the others.

In conclusion, there is indeed a variation. This variation is due to one sample, rather than one condition. In that case, the adjusted P-Value will be high and considered as non-significant. We are *not* interested in the variability on *one sample*. We are interested in the variability of one global condition.

**Case 2: Intra-class variability**

```{r fc_case_2, fig.cap = "Expression values of Gene1, condition A (blue) vs condition B (green)"}
barplot(c(2,10,4,15,13,2,20,13), names = c("S1", "S2", "S3", "S4", "S5", "S6", "S7", "S8"), col = c("lightblue", "lightblue", "lightblue", "lightblue", "seagreen", "seagreen", "seagreen", "seagreen"))
```

Here, the mean expression for the gene Gene1 for condition A is: `r mean(2, 6, 4)`. The mean expression for the gene Gene2 for condition B is: `r mean(2, 20, 4)`.

The mean expression in the two conditions are different, however, this difference is less than the expression variability within both Condition A and Condition B.

The differential expression is more likely to be between samples 1, 3, and 6 in one hand, and 2, 4, 5, 7 and 8 in the other hand.

In conclusion, there is indeed a variation. This variation seems not related to our hypothesis, rather than an unknown factor. This unknown factor is called "confounding factor". In this case, the adjusted P-Value will be high and, therefore, non significant.

**Case 3: Simpson Paradox**

In this case, we have nested conditions. Let's imagine a tumor, which can be treated by either chemotherapy or surgery. We want to know which one perform better. For the last 1000 treated patients, you will find below the success rate of each of these methods:

+---------------+----------------+--------------+---------------+
| Treatment     | Nb. recoveries | Nb. failures | Recovery rate |
+===============+================+==============+===============+
| Chemotherapy  | 761            | 239          | 76%           |
+---------------+----------------+--------------+---------------+
| Surgery       | 658            | 342          | 66%           |
+---------------+----------------+--------------+---------------+

It seems clear that the chemotherapy performs better than surgery.

However, if you consider the tumor size, the numbers are the following:

+--------------+---------------+----------------+--------------+---------------+
| Treatment    | Tumor size    | Nb. recoveries | Nb. failures | Recovery rate |
+==============+===============+================+==============+===============+
| Chemotherapy | \> 2cm (large) | 90             | 92           | 49%           |
+--------------+---------------+----------------+--------------+---------------+
| Chemotherapy | < 2cm (small) | 564            | 331          | 63%           |
+--------------+---------------+----------------+--------------+---------------+
| Surgery      | \> 2cm (large) | 94             | 11           | 90%           |
+--------------+---------------+----------------+--------------+---------------+
| Surgery      | < 2cm (small) | 671            | 147          | 82%           |
+--------------+---------------+----------------+--------------+---------------+

Now, considering the tumor size, the surgery always perform better! You can check the numbers, both table talk about the very same numbers!

Taking the number in one table or the other changes the conclusion, how to decide ?! How can chemotherapy perform better while, taking into account the tumor size, surgery outperforms ? This is called the Simpson paradox.

There are two possible observations here:

*   Smaller tumors have a higher recovery rate, which is not surprising.
*   On large tumors, surgery is used more often than chemotherapy.

So, surgery performs better, however, it is used more often on difficult cases.

Here, "Treatment" is our factor of interest. "Tumor size" is a confounding factor. Surgery is used on larger tumors. The tumor size acts on both, cause and consequence in our analysis.

Conclusion:

If your bioinformatician chose to keep a given additional factor in your analysis, there is a reason. If a gene of interest appears while and only while this additional factor is (is is not) taken into account, you cannot chose the differential analysis you prefer in order to satisfy your initial hypothesis. You could fall under this kind of statistical traps. Your bioinformatician is here to help you!

See:

1. Pearl, Judea. "Simpson's paradox, confounding, and collapibility." Causality: models, reasoning and inference 7 (2000): 173-200.
1. Axelson, O. ["Confounding from smoking in occupational epidemiology."](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1009818/) British journal of industrial medicine 46.8 (1989): 505.
1. Love, Michael I., Wolfgang Huber, and Simon Anders. ["Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2."](https://link.springer.com/article/10.1186/s13059-014-0550-8) Genome biology 15.12 (2014): 550.


#### P-Value, Adjusted P-Value and Q-Value

P-Values and Q-Values are metrics used to rank observation from 0 (effective difference) to 1 (purely random observation). A Q-Value is a P-Value adjusted using an optimized FDR (False Discovery Rate) approach.

A P-Value of 0.05 implies that 5% of all tests will result in false positives. A Q-Value of 0.05 implies that 5% of significant tests will result in false positives. The second includes a lot less of false positive.

Let us imagine an experiment with e 3516. If we take the compound number 1723, we see that it has a p-value of 0.0101 and a q-value of 0.0172. Recall that a p-value of 0.0101 implies a 1.01% chance of false positives, and so with 3516 compounds, we expect about 36 false positives, i.e. 3516 × 0.0101 = 35.51. In this experiment, there are 800 compounds with a value of 0.0101 or less, and so 36 of these will be false positives.

On the other hand, the q-value is 0.0172, which means we should expect 1.72% of all the compounds with q-value less than this to be false positives. This is a much better situation. We know that 800 compounds have a q-value of 0.0172 or less and so we should expect 800 × 0.0172 = 13.76 false positives rather than the predicted 36.

Always consider Q-Values or Adjusted P-Values rather than (raw) P-Values.

See:

1. Storey, J. D., & Tibshirani, R. (2003). [Statistical significance for genomewide studies.](http://www.pnas.org/content/100/16/9440.short) Proceedings of the National Academy of Sciences, 100(16), 9440-9445.
1. Benjamini, Yoav, and Yosef Hochberg. ["Controlling the false discovery rate: a practical and powerful approach to multiple testing."](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1995.tb02031.x) Journal of the Royal statistical society: series B (Methodological) 57.1 (1995): 289-300.
