import sys
from pathlib import Path

worflow_source_dir = Path(next(iter(workflow.get_sources()))).absolute().parent
common = str(worflow_source_dir / "../../../../bigr_pipelines/common/python")
sys.path.append(common)

from file_manager import *

default_config_vcf_post_process = {
    "ncbi_build": "GRCh38",
    "center": "GustaveRoussy",
    "annotation_tag": "ANN=",
    "sample_list": list(),
    "genome": "/path/to/ref.fasta",
    "known": "/path/to/dbsnp",
    "gatk_filters": {},
    "chr": list()
}

try:
    if config == dict():
        config = default_config_vcf_post_process
except NameError:
    config = default_config_vcf_post_process

"""
Compress and index final VCF files
"""
rule gath_final_vcf:
    input:
        expand(
            "maf/canonical/{sample}.vcf.gz",
            sample=config["sample_list"]
        ),
        expand(
            "maf/canonical/{sample}.vcf.gz.tbi",
            sample=config["sample_list"]
        )
    output:
        "final.vcf.list"
    message:
        "Aquiring list of final VCF files"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 128,
        time_min=lambda wildcards, attempt: attempt * 15,
        tmpdir="tmp"
    log:
        "logs/somatic/list.log"
    shell:
        "echo {input} > {output} 2> {log}"


"""
Big concatenation for maftools
"""
rule concat_all_mafs:
    input:
        expand(
            "maf/maftools/{sample}.maf",
            sample=config["sample_list"]
        )
    output:
        "maf/maftools/complete.maf"
    message:
        "Merging separates maf files in a single cohort maf"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 1024,
        time_min=lambda wildcards, attempt: attempt * 15,
        tmpdir="tmp"
    log:
        "logs/maftools/concat.log"
    shell:
        "cat {input} > {output} 2> {log}"


"""
Assure MAFtools compatibility and human readability
"""
rule rename_snpsift_maf_cols:
    input:
        tsv="maf/extracted/{sample}.tsv"
    output:
        tsv="maf/maftools/{sample}.maf"
    message:
        "Renaming columns to fit MAFtools requirement in {wildcards.sample}"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 1024 * 5,
        time_min=lambda wildcards, attempt: attempt * 15,
        tmpdir="tmp"
    group:
        "vcf_to_maf"
    log:
        "logs/maftools/rename/{sample}.log"
    params:
        add_cols=True,
        ncbi_build=config.get("NBCI_build", "GRCh38"),
        center=config.get("center", "GustaveRoussy"),
        Tumor_Sample_Barcode=lambda wildcards: f"{wildcards.sample}_tumor",
        Matched_Norm_Sample_Barcode=lambda wildcards: f"{wildcards.sample}_normal"
    wrapper:
        "bio/BiGR/rename_snpsift_maf_cols"




"""
Extracting all INFO/FORMAT data, the list is built from vcf header
"""
rule extract_all_fields:
    input:
        call="maf/canonical/{sample}.vcf"
    output:
        tsv=temp("maf/extracted/{sample}.tsv")
    message:
        "Extracting variant annotations for {wildcards.sample}"
    threads: 2
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 10240,
        time_min=lambda wildcards, attempt: attempt * 25,
        tmpdir="tmp"
    group:
        "vcf_to_maf"
    log:
        "logs/snpsift/extract_all_fields/{sample}.log"
    params:
        annotation_tag=config.get("annotation_tag", "ANN="),
        ignore_format=True
    wrapper:
        "bio/snpsift/extractAllFields"


"""
Remove non-canonical chromosomes, and empty info fields
"""
rule fix_vcf:
    input:
        vcf="maf/splitted/{sample}.vcf"
    output:
        vcf=temp("maf/canonical/{sample}.vcf")
    message:
        "Cleaning {wildcards.sample}"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 1024,
        time_min=lambda wildcards, attempt: attempt * 15,
        tmpdir="tmp"
    group:
        "GLeaves"
    log:
        "logs/fix_vcf/{sample}.log"
    params:
        default_chr=
        remove_non_conventional_chromosomes=True
    wrapper:
        "bio/BiGR/fix_vcf"


"""
Split annotation since it may lead to errors in MAFtools and/or in a result
file more difficult to read by a human.
"""
rule split_vcf_features:
    input:
        call="snpsift/format2info/{sample}.vcf"
    output:
        call=temp("maf/splitted/{sample}.vcf")
    message:
        "Splitting variant annotations for {wildcards.sample}"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 1024,
        time_min=lambda wildcards, attempt: attempt * 15,
        tmpdir="tmp"
    group:
        "GLeaves"
    log:
        "logs/split_vcf_features/{sample}.log"
    params:
        annotation_tag="ANN="
    wrapper:
        "bio/BiGR/split_vcf_features"


"""
Copy format information, this is for end-users reading
"""
rule format_to_info:
    input:
        call = "gatk/variant_filtration/{sample}.vcf"
    output:
        call = temp("snpsift/format2info/{sample}.vcf")
    message:
        "Moving format fields to info for {wildcards.sample}"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 2048,
        time_min=lambda wildcards, attempt: attempt * 45,
        tmpdir="tmp"
    group:
        "GLeaves"
    log:
        "logs/vcf_format_to_info/{sample}.log"
    wrapper:
        "bio/BiGR/vcf_format_to_info"


"""
Variant calling quality control
"""
rule gatk_variant_evaluation:
    input:
        vcf="gatk/variant_filtration/{sample}.vcf.gz",
        vcf_tbi=get_tbi("gatk/variant_filtration/{sample}.vcf.gz"),
        bam="picard/markduplicates/{sample}_tumor.bam",
        bai=get_bai("picard/markduplicates/{sample}_tumor.bam"),
        ref=config["genome"],
        fai=get_fai(config["genome"]),
        dict=get_dict(config["genome"]),
        known=config["known"],
        known_tbi=get_tbi(config["known"])
    output:
        directory("gatk_variant_evaluation/{sample}")
    message:
        "Evaluating variant calling of {wildcards.sample}"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 1024,
        time_min=lambda wildcards, attempt: attempt * 15,
        tmpdir="tmp"
    group:
        "GATK_Stats"
    log:
        "logs/gatk/varianteval/{sample}.log"
    params:
        extra=""
    wrapper:
        "bio/gatk/varianteval"


"""
Add filter tags, these filters do not remove variants, only annotates
"""
rule gatk_variant_filtration:
    input:
        vcf="snpsift/annotate_corrected/{sample}.vcf.gz",
        vcf_tbi=get_tbi("snpsift/annotate_corrected/{sample}.vcf.gz"),
        ref=config["genome"]
    output:
        vcf=temp("gatk/variant_filtration/{sample}.vcf")
    message:
        "Filtering VCF for {wildcards.sample}"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 10240,
        time_min=lambda wildcards, attempt: attempt * 25,
        tmpdir="tmp"
    group:
        "GATK_Stats"
    log:
        "logs/gatk/variant_filtration/{sample}.log"
    params:
        filters=config.get("gatk_filters", {
            "DepthBelow60X": "DP < 59",
            "BelowQualByDepth": "QD <= 2.0",
            "BelowBaseQuality": "QUAL < 30.0",
            "AboveFisherStrandBias": "FS > 60.0",
            "AboveStrandOddsRatio": "SOR > 3.0",
            "BelowMappingQuality": "MQ < 35.0",
            "BelowMQRankSum": "MQRankSum < -12.5",
            "BelowReadPosRankSum": "ReadPosRankSum < -8.0"
        })
    wrapper:
        "bio/gatk/variantfiltration"


rule fix_annotation_for_gatk:
    input:
        call="snpsift/dbnsfp/{sample}.vcf.gz",
        tbi=get_tbi("snpsift/dbnsfp/{sample}.vcf.gz")
    output:
        call=temp("snpsift/annotate_corrected/{sample}.vcf")
    message:
        "Correcting annotation type error in {wildcards.sample}"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 512,
        time_min=lambda wildcards, attempt: attempt * 25,
        tmpdir="tmp"
    params:
        remove_list=[
            "END=\([0-9]\+,\?\)\+"
        ],
        replace_dict={
            ";;": ";",
            ";\t": "\t",
            "ID=CLNV": "ID=clinvar_CLNV",
            "ID=ALLELID": "ID=clinvar_ALLELEID"
        }
    group:
        "GATK_Stats"
    log:
        "logs/snpsift/annotate_corrected/{sample}.log"
    wrapper:
        "bio/sed"
