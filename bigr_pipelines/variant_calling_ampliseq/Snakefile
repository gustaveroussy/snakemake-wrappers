import sys

sys.path.append("/mnt/beegfs/pipelines/snakemake-wrappers/bigr_pipelines/common/python/")

from file_manager import (
    read_design,
    get_fasta_index_from_genome_path,
    get_fasta_dict_from_genome_path,
    get_vcf_tbi_from_vcf_path
)
from files_linker import link_fq
from write_yaml import write_yaml_from_path
from pathlib import Path
from snakemake.utils import min_version
min_version("6.0")

container: "docker://continuumio/miniconda3:4.4.10"

configfile: "config.yaml"

localrules: bigr_copy

design = read_design("design.tsv")

config_path = Path("config_variant_calling_ampliseq.yaml")
if not config_path.exists() or True:
    write_yaml_from_path(config_path, config)

configfile: config_path

localrules: bigr_copy

wildcard_constraints:
    sample = r"|".join(design["Sample_id"]),
    stream = r"1|2"

fastq_links = link_fq(
    design.Sample_id,
    design.Upstream_file,
    design.Downstream_file
)

rule all:
    input:
        #expand(
        #    "snpsift/gwascat/{sample}.vcf.gz",
        #    sample=design["Sample_id"]
        #),
        expand(
            "snpsift/gwascat/{sample}.vcf.gz",
            #"snpsift/cosmic/{sample}.vcf",
            #stream=["1", "2"],
            sample=design["Sample_id"]
        )
    message:
        "Finishing the Ampliseq variant calling"

#################
### Gather QC ###
#################

use rule multiqc from snpeff_snpsift_meta with:
    input:
        html=expand(
            "fastp/html/pe/{sample}.fastp.html",
            sample=design["Sample_id"]
        ),
        json=expand(
            "fastp/json/pe/{sample}.fastp.json",
            sample=design["Sample_id"]
        ),
        picard=expand(
            "picard/alignment_summary/{sample}.summary.txt",
            sample=design["Sample_id"]
        )


rule alignment_summary:
    input:
        bam="samtools/sort/{sample}.bam",
        bam_index="samtools/sort/{sample}.bam.bai",
        ref=config['ref']['fasta'],
        ref_idx=get_fasta_index_from_genome_path(config['ref']['fasta']),
        ref_dict=get_fasta_dict_from_genome_path(config['ref']['fasta']),
    output:
        temp("picard/alignment_summary/{sample}.summary.txt")
    message:
        "Collecting alignment metrics on GATK recalibrated {wildcards.sample}"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 1020,
        time_min=lambda wildcards, attempt: attempt * 45
    log:
        "logs/picard/alignment_summary/{sample}.log"
    params:
        "VALIDATION_STRINGENCY=LENIENT "
        "METRIC_ACCUMULATION_LEVEL=null "
        "METRIC_ACCUMULATION_LEVEL=SAMPLE"
    wrapper:
        "/bio/picard/collectalignmentsummarymetrics"


#################################
### FINAL VCF FILE INDEXATION ###
#################################

rule tabix_index:
    input:
        "snpsift/gwascat/{sample}.vcf.gz"
    output:
        "snpsift/gwascat/{sample}.vcf.gz.tbi"
    message:
        "Indexing {wildcards.sample} final annotated VCF with tabix"
    group:
        "Final_compression_{sample}"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 1020,
        time_min=lambda wildcards, attempt: attempt * 45
    log:
        "logs/pbgzip/post_gwascat/{sample}.log"
    wrapper:
        "/bio/tabix"


rule compress_pbgzip:
    input:
        "snpsift/gwascat/{sample}.vcf"
    output:
        "snpsift/gwascat/{sample}.vcf.gz"
    message:
        "Compressing {wildcards.sample} final annotated VCF with pbgzip"
    group:
        "Final_compression_{sample}"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 1020,
        time_min=lambda wildcards, attempt: attempt * 45
    log:
        "logs/pbgzip/post_gwascat/{sample}.log"
    wrapper:
        "/bio/compress/pbgzip"

###########################
### VCF FILE ANNOTATION ###
###########################

module snpeff_snpsift_meta:
    snakefile: "../snpeff_snpsift/Snakefile.smk"
    config: config

use rule * from snpeff_snpsift_meta as snpeff_snpsift_*


###############################
### VARIANT CALLING VARSCAN ###
###############################

module varscan2_calling_meta:
    snakefile: "../../meta/bio/varscan2_calling/test/Snakefile"
    config: {"genome": config["ref"]["fasta"], "bed": config["ref"]["capture_kit_bed"]}

use rule * from varscan2_calling_meta as *

use rule samtools_mpilup from varscan2_calling_meta with:
    input:
        bam="gatk/recal_bam/{sample}.bam",
        reference_genome=config['ref']['fasta'],
        reference_genome_idx=get_fasta_index_from_genome_path(config['ref']['fasta']),


##############################
### GATK BAM RECALIBRATION ###
##############################

module gatk_bqsr_meta:
    snakefile: "../../meta/bio/gatk_bqsr/test/Snakefile"
    config: {"threads": config["threads"], "genome": config["ref"]["fasta"], "dbsnp": config["ref"]["dbsnp"]}


use rule gatk_apply_baserecalibrator from gatk_bqsr_meta with:
    input:
        bam="samtools/sort/{sample}.bam",
        bam_index="samtools/sort/{sample}.bam.bai",
        ref=config['ref']['fasta'],
        ref_idx=get_fasta_index_from_genome_path(config['ref']['fasta']),
        ref_dict=get_fasta_dict_from_genome_path(config['ref']['fasta']),
        recal_table="gatk/recal_data_table/{sample}.grp"


use rule gatk_compute_baserecalibration_table from gatk_bqsr_meta with:
    input:
        bam="samtools/sort/{sample}.bam",
        bam_index="samtools/sort/{sample}.bam.bai",
        ref=config['ref']['fasta'],
        ref_idx=get_fasta_index_from_genome_path(config['ref']['fasta']),
        ref_dict=get_fasta_dict_from_genome_path(config['ref']['fasta']),
        known=config['ref']['dbsnp'],
        known_idx=get_vcf_tbi_from_vcf_path(config['ref']['dbsnp'])


###################
### BWA MAPPING ###
###################

module bwa_fixmate_meta:
    snakefile: "../../meta/bio/bwa_fixmate/test/Snakefile"
    config: {"threads": config["threads"], "genome": config["ref"]["fasta"]}

use rule * from bwa_fixmate_meta as bwa_fixmate_meta_*

use rule bwa_mem from bwa_fixmate_meta with:
    input:
        reads=expand(
            "fastp/trimmed/pe/{sample}.{stream}.fastq",
            stream=["1", "2"],
            allow_missing=True
        ),
        index=multiext(
            "bwa_mem2/index/genome", ".0123", ".amb", ".ann", ".pac"
        )


############################
### FASTP FASTQ CLEANING ###
############################

rule fastp_clean:
    input:
        sample=expand(
            "reads/{sample}.{stream}.fq.gz",
            stream=["1", "2"],
            allow_missing=True
        ),
    output:
        trimmed=expand(
            "fastp/trimmed/pe/{sample}.{stream}.fastq",
            stream=["1", "2"],
            allow_missing=True
        ),
        html="fastp/html/pe/{sample}.fastp.html",
        json=temp("fastp/json/pe/{sample}.fastp.json")
    message: "Cleaning {wildcards.sample} with Fastp"
    threads: 1
    resources:
        mem_mb=lambda wildcard, attempt: min(attempt * 4096, 15360),
        time_min=lambda wildcard, attempt: attempt * 45
    params:
        adapters=config.get("fastp_adapters", None),
        extra=config.get("fastp_extra", "")
    log:
        "logs/fastp/{sample}.log"
    wrapper:
        "/bio/fastp"


#################################################
### Gather files from iRODS or mounting point ###
#################################################

rule bigr_copy:
    output:
        "reads/{sample}.{stream}.fq.gz"
    message:
        "Gathering {wildcards.sample} fastq file ({wildcards.stream})"
    threads: 1
    resources:
        mem_mb=lambda wildcard, attempt: min(attempt * 1024, 2048),
        time_min=lambda wildcard, attempt: attempt * 45
    params:
        input=lambda wildcards, output: fastq_links[output[0]]
    log:
        "logs/bigr_copy/{sample}.{stream}.log"
    wrapper:
        "/bio/BiGR/copy"
