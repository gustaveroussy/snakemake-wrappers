from snakemake.utils import min_version
from pathlib import Path
from yaml import dump
min_version("6.0")

import sys

worflow_source_dir = Path(next(iter(workflow.get_sources()))).absolute().parent
common = str(worflow_source_dir / "../common/python")
sys.path.append(common)

from file_manager import *
from files_linker import *
from write_yaml import *
from messages import message

logging.basicConfig(
    filename="snakemake.salmon_quant.log",
    filemode="w",
    level=logging.DEBUG
)

default_config = read_yaml(worflow_source_dir / "config.hg38.yaml")
configfile: get_config(default_config)
design = get_design(os.getcwd(), search_fastq_pairs)

try:
    fastq_links = link_fq(
        design.Sample_id,
        design.Upstream_file,
        design.Downstream_file
    )

    ruleorder: salmon_quant_paired > salmon_quant_single
    ruleorder: multiqc > multiqc_single
    ruleorder: fastp_clean > fastp_clean_single_end
except AttributeError:
    fastq_links = link_fq(
        design.Sample_id,
        design.Upstream_file
    )

    ruleorder: salmon_quant_single > salmon_quant_paired
    ruleorder: multiqc_single > multiqc
    ruleorder: fastp_clean_single_end > fastp_clean

#print(fastq_links)


wildcard_constraints:
    sample=r"|".join(design.Sample_id.to_list()),
    stream=r"|".join(map(str, range(3)))

rule target:
    input:
        "multiqc/MultiQC.html",
        "salmon/TPM.genes.tsv",
        "salmon/TPM.transcripts.tsv"
    output:
        directory("results_to_upload")
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 512,
        time_min=lambda wildcards, attempt: attempt * 25,
        tmpdir="tmp"
    log:
        "logs/results_to_upload.log"
    params:
        "--verbose --checksum --human-readable"
    shell:
        "rsync {params} {input} {output} > {log} 2>&1"


########################
### Aggregate counts ###
########################


rule aggregate_gene_counts:
    input:
        quant=expand(
            "salmon/pseudo_mapping/{sample}/quant.genes.sf",
            sample=design["Sample_id"]
        ),
        tx2gene="salmon/tx2gene.tsv"
    output:
        tsv="salmon/TPM.genes.tsv"
    message:
        "Aggregating genes counts with their gene names"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 1024 * 4,
        time_min=lambda wildcards, attempt: attempt * 15,
        tmpdir="tmp"
    params:
        header=False,
        position=False,
        gencode=True,
        genes=True,
        index_label=True,
        fillna="Unknown"
    log:
        "logs/aggregate/genes.log"
    wrapper:
        "bio/pandas/salmon"


rule aggregate_transcript_counts:
    input:
        quant=expand(
            "salmon/pseudo_mapping/{sample}/quant.sf",
            sample=design["Sample_id"]
        ),
        tx2gene="salmon/tx2gene.tsv"
    output:
        tsv="salmon/TPM.transcripts.tsv"
    message:
        "Aggregating transcript counts with their gene names"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 1024 * 4,
        time_min=lambda wildcards, attempt: attempt * 15,
        tmpdir="tmp"
    params:
        header=False,
        position=False,
        gencode=True,
        genes=False,
        index_label=True
    log:
        "logs/aggregate/transcripts.log"
    wrapper:
        "bio/pandas/salmon"


rule tx_to_gene:
    input:
        gtf = config["ref"]["gtf"]
    output:
        tx2gene = temp("salmon/tx2gene.tsv"),
        tx2gene_large = temp("salmon/tx2gene_with_positions.tsv"),
        gene2gene = temp("salmon/gene2gene.tsv"),
        gene2gene_large = temp("salmon/gene2gene_with_chr.tsv")
    message:
        "Gathering transcripts and genes names together from GTF"
    threads: 1
    resources:
        mem_mb = lambda wildcards, attempt: attempt * 1024 * 4,
        time_min = lambda wildcards, attempt: min(attempt * 10, 15),
        tmpdir="tmp"
    log:
        "logs/tx_to_gene.log"
    wrapper:
        "bio/gtf/tx2gene"


########################
### Quality Controls ###
########################


rule multiqc:
    input:
        salmon=expand(
            "salmon/pseudo_mapping/{sample}/quant.sf",
            sample=design["Sample_id"]
        ),
        html=expand(
            "fastp/html/pe/{sample}.fastp.html",
            sample=design["Sample_id"]
        ),
        json=expand(
            "fastp/json/pe/{sample}.fastp.json",
            sample=design["Sample_id"]
        ),
        fastq_screen=expand(
            "fastq_screen/{sample}.{stream}.fastq_screen.{ext}",
            sample=design["Sample_id"],
            stream=["1", "2"],
            ext=["txt", "png"]
        )
    output:
        report(
            "multiqc/MultiQC.html",
            caption="../common/reports/multiqc.rst",
            category="Quality Controls"
        )
    message:
        "Aggregating quality reports from Fastp and Salmon"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: min(attempt * 1536, 10240),
        time_min=lambda wildcards, attempt: attempt * 35,
        tmpdir="tmp"
    log:
        "logs/multiqc.log"
    wrapper:
        "bio/multiqc"


use rule multiqc as multiqc_single with:
    input:
        salmon=expand(
            "salmon/pseudo_mapping/{sample}/quant.sf",
            sample=design["Sample_id"]
        ),
        html=expand(
            "fastp/html/pe/{sample}.fastp.html",
            sample=design["Sample_id"]
        ),
        json=expand(
            "fastp/json/pe/{sample}.fastp.json",
            sample=design["Sample_id"]
        ),
        fastq_screen=expand(
            "fastq_screen/{sample}.fastq_screen.{ext}",
            sample=design["Sample_id"],
            ext=["txt", "png"]
        )
    output:
        report(
            "multiqc/MultiQC.html",
            caption="../common/reports/multiqc.rst",
            category="Quality Controls"
        )



rule fastq_screen:
    input:
        "reads/{sample}.{stream}.fq.gz"
    output:
        txt=temp("fastq_screen/{sample}.{stream}.fastq_screen.txt"),
        png=temp("fastq_screen/{sample}.{stream}.fastq_screen.png")
    message:
        "Assessing quality of {wildcards.sample}, stream {wildcards.stream}"
    threads: config.get("threads", 20)
    resources:
        mem_mb=lambda wildcard, attempt: min(attempt * 1024 * 8, 8192),
        time_min=lambda wildcard, attempt: attempt * 75,
        tmpdir="tmp"
    params:
        fastq_screen_config=config["fastq_screen"],
        subset=100000,
        aligner='bowtie2'
    log:
        "logs/fastq_screen/{sample}.{stream}.log"
    wrapper:
        "bio/fastq_screen"


use rule fastq_screen as fastq_screen_single with:
    input:
        "reads/{sample}.fq.gz"
    output:
        txt=temp("fastq_screen/{sample}.fastq_screen.txt"),
        png=temp("fastq_screen/{sample}.fastq_screen.png")
    message:
        "Assessing quality of {wildcards.sample}"
    log:
        "logs/fastq_screen/{sample}.log"


#############################
### Salmon quantification ###
#############################

salmon_config = {
    "genome": config["ref"]["genome"],
    "transcriptome": config["ref"]["transcriptome"],
    "gtf": config["ref"]["gtf"],
    "salmon_libtype": config["params"]["salmon_libtype"],
    "salmon_quant_extra": config["params"]["salmon_quant_extra"],
    "salmon_index_extra": config["params"]["salmon_index_extra"]
}


module salmon_meta:
    snakefile: "../../meta/bio/salmon/test/Snakefile"
    config: salmon_config


use rule * from salmon_meta


use rule salmon_quant_paired from salmon_meta with:
    output:
        quant=report(
            "salmon/pseudo_mapping/{sample}/quant.sf",
            category="2. Raw Salmon output",
            caption="../../common/reports/salmon_quant.rst"
        ),
        quant_genes="salmon/pseudo_mapping/{sample}/quant.genes.sf",
        lib="salmon/pseudo_mapping/{sample}/lib_format_counts.json",
        #mapping=temp("salmon/bams/{sample}.bam")


use rule salmon_quant_paired from salmon_meta as salmon_quant_single with:
    input:
        r="reads/{sample}.fq.gz",
        index=config["ref"].get("salmon_index", "salmon/index"),
        gtf=config["ref"]["gtf"]
    output:
        quant=report(
            "salmon/pseudo_mapping/{sample}/quant.sf",
            category="2. Raw Salmon output",
            caption="../../common/reports/salmon_quant.rst"
        ),
        quant_genes="salmon/pseudo_mapping/{sample}/quant.genes.sf",
        lib="salmon/pseudo_mapping/{sample}/lib_format_counts.json",
        #mapping=temp("salmon/bams/{sample}.bam")


############################
### FASTP FASTQ CLEANING ###
############################

rule fastp_clean:
    input:
        sample=expand(
            "reads/{sample}.{stream}.fq.gz",
            stream=["1", "2"],
            allow_missing=True
        ),
    output:
        trimmed=temp(expand(
            "fastp/trimmed/pe/{sample}.{stream}.fastq",
            stream=["1", "2"],
            allow_missing=True
        )),
        html="fastp/html/pe/{sample}.fastp.html",
        json="fastp/json/pe/{sample}.fastp.json"
    message: "Cleaning {wildcards.sample} with Fastp"
    threads: 1
    resources:
        mem_mb=lambda wildcard, attempt: min(attempt * 4096, 15360),
        time_min=lambda wildcard, attempt: attempt * 45,
        tmpdir="tmp"
    params:
        adapters=config["params"].get("fastp_adapters", None),
        extra=config["params"].get("fastp_extra", "")
    log:
        "logs/fastp/{sample}.log"
    wrapper:
        "bio/fastp"


use rule fastp_clean as fastp_clean_single_end with:
    input:
        sample=["reads/{sample}.fq.gz"]
    output:
        trimmed="fastp/trimmed/pe/{sample}.fastq",
        html="fastp/html/pe/{sample}.fastp.html",
        json=temp("fastp/json/pe/{sample}.fastp.json")


#################################################
### Gather files from iRODS or mounting point ###
#################################################

rule bigr_copy:
    output:
        "reads/{sample}.{stream}.fq.gz"
    message:
        "Gathering {wildcards.sample} fastq file ({wildcards.stream})"
    threads: 1
    resources:
        mem_mb=lambda wildcard, attempt: min(attempt * 1024, 2048),
        time_min=lambda wildcard, attempt: attempt * 45
    params:
        input=lambda wildcards, output: fastq_links[output[0]]
    log:
        "logs/bigr_copy/{sample}.{stream}.log"
    wrapper:
        "bio/BiGR/copy"


use rule bigr_copy as bigr_copy_single_end with:
    output:
        "reads/{sample}.fq.gz"
    message:
        "Gathering {wildcards.sample} fastq file"
    log:
        "logs/bigr_copy/{sample}.log"
